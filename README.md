ğŸ“Œ Gesture-Controlled Robot (Manual + Obstacle Avoidance Mode)

This project is a 4-wheel Arduino robot that can be controlled using hand gestures and also switch to Autonomous Obstacle Avoidance mode.
The gestures are captured using a Basic CNN model, which sends commands to the robot via Bluetooth. An ultrasonic sensor enables autonomous navigation with intelligent obstacle detection.

ğŸš€ Features

âœ… Gesture-Based Manual Control
Use hand gestures detected by a CNN model to move the robot:

Gesture/Key	Action
F / Forward Gesture	Move Forward
B / Backward Gesture	Move Backward
L / Left Gesture	Turn Left
R / Right Gesture	Turn Right
S	Stop
M	Switch to Manual Mode
A	Switch to Autonomous Mode

âœ… Autonomous Obstacle Avoidance Mode

Uses an ultrasonic sensor to detect obstacles

If obstacle in front â†’ turn right

If right also blocked â†’ turn left

If surrounded â†’ move backward

Automatically resumes forward motion when path is clear

âœ… Bluetooth Communication

Commands transmitted via HC-05/HC-06 Bluetooth module

Compatible with mobile apps or Python scripts

âœ… Motor Speed Control (Manual)

Speed adjusts using PWM based on how long command is sent

Smooth acceleration and deceleration for realistic control

ğŸ§  Tech Stack
Component	Usage
Arduino Uno / Nano	Main controller
HC-05 / HC-06	Wireless communication
L298N Motor Driver	Controls DC motors
Ultrasonic Sensor (HC-SR04)	Obstacle detection
Python + OpenCV + CNN	Hand-gesture recognition
ğŸ”§ Hardware Required
Component	Quantity
Arduino Uno / Nano	1
L298N Motor Driver	1
HC-05/HC-06 Bluetooth Module	1
HC-SR04 Ultrasonic Sensor	1
4 DC Motors + Wheels	4
Battery Pack (7.4Vâ€“12V)	1
Chassis	1
Jumper Wires	â€”
âš™ï¸ Wiring Diagram (Overview)
Arduino Pin	Connected To
D5 (PWM)	Left Motor Enable
D6 (PWM)	Right Motor Enable
D8, D9	Left Motor IN1, IN2
D10, D11	Right Motor IN3, IN4
D2, D3	Ultrasonic Trigger, Echo
RX, TX	Bluetooth TX, RX (cross connection)

Detailed wiring diagram will be added as an image in /docs/.

ğŸ“‚ Project Structure
GESTURE-CONTROLLED-ROBOT/
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ gesture_robot.ino         # Arduino code
â”‚   â””â”€â”€ cnn_gesture_control.py     # Python gesture detection + command sender
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ gesture_cnn_model.h5       # Saved CNN model
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ wiring_diagram.png
â”‚   â”œâ”€â”€ how_it_works.md
â”‚   â””â”€â”€ demo_images/
â”‚
â”œâ”€â”€ README.md                      # Project Documentation
â””â”€â”€ LICENSE

ğŸƒâ€â™‚ï¸ How to Run
Step 1: Upload Arduino Code

Open the .ino file in Arduino IDE

Select board & COM port

Upload

Step 2: Run Gesture Detection
python cnn_gesture_control.py

Step 3: Control the Robot

Perform hand gestures in front of the camera â†’ robot responds via Bluetooth.

Press A on your keyboard to switch to Auto mode.
Press M to go back to Manual mode.

ğŸ§ª Future Enhancements

ğŸš§ Add more gestures (e.g., speed boost, diagonal motion)
ğŸŸ¦ Train a more accurate CNN model
ğŸ¤– Add line-following or voice commands
ğŸ“ Add PID-based smooth motion

ğŸ“ License

This project is open-source under the MIT License.
Feel free to use, modify, or improve the project with attribution.
